{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from llama_cpp import Llama\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# ------------- LLM RESPONSE GENERATION -------------\n",
    "\n",
    "def generate_recipe_fallback(\n",
    "    fridge_items: Dict[str, int],\n",
    "    preferences: Dict[str, str],\n",
    "    llm_model: Any\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a fallback recipe suggestion when no good matches are found.\n",
    "\n",
    "    Args:\n",
    "        fridge_items: Dictionary of available fridge items with quantities (e.g., {'apple': 1, 'ketchup': 3})\n",
    "        preferences: Dictionary of user preferences (e.g., {'mealType': 'Dessert', 'dietaryNeeds': 'Low-carb'})\n",
    "        llm_model: Loaded Llama 3.2 model\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with fallback recipe information\n",
    "    \"\"\"\n",
    "    # Prepare lists for available ingredients and dietary restrictions\n",
    "    available_ingredients = list(fridge_items.keys())  # Use keys as ingredients\n",
    "    dietary_restrictions = [preferences['dietaryNeeds']]  # Use dietaryNeeds from preferences\n",
    "\n",
    "    # Create prompt for the LLM to generate a recipe\n",
    "    ingredients_list = \", \".join(available_ingredients[:15])  # Limit to first 15 ingredients\n",
    "    restrictions_list = \", \".join(dietary_restrictions)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Create a simple recipe that meets these requirements:\n",
    "\n",
    "    Available ingredients: {ingredients_list}\n",
    "    Dietary restrictions: {restrictions_list}\n",
    "    User request: {preferences['mealType']} with {preferences['mainIngredient']} as the main ingredient and {preferences['dishType']} as the dish type.\n",
    "\n",
    "    Return ONLY a JSON object with this exact format:\n",
    "    {{\n",
    "      \"name\": \"Recipe name\",\n",
    "      \"ingredients\": [\"ingredient1\", \"ingredient2\", ...],\n",
    "      \"steps\": \"Step-by-step instructions\",\n",
    "      \"tags\": \"comma,separated,tags\",\n",
    "      \"notes\": \"Any special notes about dietary restrictions\"\n",
    "    }}\n",
    "\n",
    "    The recipe should use as many of the available ingredients as possible while respecting all dietary restrictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response with Llama 3.2\n",
    "    try:\n",
    "        response = llm_model.create_completion(\n",
    "            prompt,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            stop=[\"```\", \"User:\"]\n",
    "        )\n",
    "\n",
    "        # Parse JSON response\n",
    "        response_text = response['choices'][0]['text'].strip()\n",
    "        # Extract JSON if embedded in text\n",
    "        if \"```json\" in response_text:\n",
    "            json_str = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"{\" in response_text and \"}\" in response_text:\n",
    "            json_str = response_text[response_text.find(\"{\"):response_text.rfind(\"}\")+1]\n",
    "        else:\n",
    "            json_str = response_text\n",
    "\n",
    "        fallback_recipe = json.loads(json_str)\n",
    "\n",
    "        # Add fallback flag\n",
    "        fallback_recipe[\"is_fallback\"] = True\n",
    "        fallback_recipe[\"combined_score\"] = 0.5  # Arbitrary middle score\n",
    "\n",
    "        return fallback_recipe\n",
    "    except Exception as e:\n",
    "        # If JSON parsing fails, return a basic fallback\n",
    "        print(f\"Error generating fallback recipe: {str(e)}\")\n",
    "        return {\n",
    "            \"name\": \"Simple \" + preferences['dietaryNeeds'] + \" Recipe\",\n",
    "            \"ingredients\": available_ingredients[:5],\n",
    "            \"steps\": \"Combine available ingredients to taste.\",\n",
    "            \"tags\": preferences['dietaryNeeds'],\n",
    "            \"notes\": \"This is a basic recipe using your available ingredients.\",\n",
    "            \"is_fallback\": True,\n",
    "            \"combined_score\": 0.5\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recipe_query(\n",
    "    fridge_items: Dict[str, int],\n",
    "    preferences: Dict[str, str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Main function to process a user query about recipes.\n",
    "\n",
    "    Args:\n",
    "        fridge_items: Dictionary of available fridge items\n",
    "        preferences: Dictionary of user preferences\n",
    "\n",
    "    Returns:\n",
    "        Natural language response with recipe recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load models and data\n",
    "        llm_model = Llama(\n",
    "            model_path=\"/path/to/your/llama-3.2-8b.gguf\",  # Absolute path to model\n",
    "            n_ctx=4096,  # Context window\n",
    "            n_gpu_layers=-1  # Use all available GPU layers if possible\n",
    "        )\n",
    "\n",
    "        # Generate fallback recipe based on the input\n",
    "        fallback_recipe = generate_recipe_fallback(\n",
    "            fridge_items=fridge_items,\n",
    "            preferences=preferences,\n",
    "            llm_model=llm_model\n",
    "        )\n",
    "\n",
    "        # Convert fallback recipe to a user-friendly response\n",
    "        response = f\"Here is a recipe suggestion based on your preferences and ingredients:\\n\\n\"\n",
    "        response += f\"Recipe Name: {fallback_recipe['name']}\\n\"\n",
    "        response += f\"Ingredients: {', '.join(fallback_recipe['ingredients'])}\\n\"\n",
    "        response += f\"Steps: {fallback_recipe['steps']}\\n\"\n",
    "        response += f\"Tags: {fallback_recipe['tags']}\\n\"\n",
    "        response += f\"Notes: {fallback_recipe['notes']}\\n\"\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"An unexpected error occurred: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return \"I'm sorry, I encountered an unexpected error. Please try again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fridge_items = {\"apple\": 1, \"ketchup\": 3, \"cucumber\": 3, \"chicken\": 2}\n",
    "preferences = {\n",
    "    \"mealType\": \"Dinner\",\n",
    "    \"dietaryNeeds\": \"Low-carb\",\n",
    "    \"cuisineType\": \"None\",\n",
    "    \"mainIngredient\": \"Chicken\",\n",
    "    \"dishType\": \"Casserole\"\n",
    "}\n",
    "\n",
    "# Process the recipe query and print the response\n",
    "response = process_recipe_query(fridge_items, preferences)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
